{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d3d157",
   "metadata": {},
   "source": [
    "# ❗ 최종 선택 모델 훈련 요약\n",
    "\n",
    "## 모델 구조\n",
    "- Conv2D(64, 3x3, ReLU) + BatchNormalization + MaxPooling2D\n",
    "- Conv2D(96, 3x3, ReLU) + BatchNormalization + MaxPooling2D\n",
    "- Flatten\n",
    "- Dense(32, ReLU) + L2 정규화(0.001) + Dropout(0.4)\n",
    "- Dense(1, Sigmoid)\n",
    "\n",
    "## 주요 하이퍼파라미터\n",
    "- 이미지 입력 크기: 86x86  \n",
    "- Batch Size: 32  \n",
    "- Optimizer: Adam(learning_rate=0.0005)  \n",
    "- loss: binary_crossentropy  \n",
    "- Epoch 수: 20  \n",
    "- Seed 고정: 42  \n",
    "\n",
    "## 데이터 전처리 및 제너레이터 설정\n",
    "- ImageDataGenerator를 사용한 데이터 증강  \n",
    "  - rescale: 1./255\n",
    "  - brightness_range: [0.7, 1.3]\n",
    "  - rotation_range: 10\n",
    "  - zoom_range: 0.1\n",
    "  - width/height_shift_range: 0.1\n",
    "  - fill_mode: 'nearest'\n",
    "- grayscale 모드로 불러옴\n",
    "- train/val split 비율: 80% / 20%\n",
    "\n",
    "## 성능 평가\n",
    "- Accuracy/Loss 그래프 시각화 및 저장  \n",
    "- Classification Report 출력 및 저장  \n",
    "- Confusion Matrix 시각화 및 저장  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446bcd52",
   "metadata": {},
   "source": [
    "# Import Library + Seed Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "SEED=42\n",
    "os.environ[\"PYTHONHASHSEED\"]=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995be5cf",
   "metadata": {},
   "source": [
    "# Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f169ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus=tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83223844",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b376c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=86\n",
    "BATCH_SIZE=32\n",
    "DATA_PATH=\"../../data/processed\"\n",
    "\n",
    "datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    horizontal_flip=False,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator=datagen.flow_from_directory(\n",
    "    DATA_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator=datagen.flow_from_directory(\n",
    "    DATA_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5214f7",
   "metadata": {},
   "source": [
    "# Define Model (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Conv2D(64, 3, activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2),\n",
    "\n",
    "    Conv2D(96, 3, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "            loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62043383",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_generator, validation_data=val_generator,\n",
    "                epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0923f6",
   "metadata": {},
   "source": [
    "# Accuracy/Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../results/images/training_plot_final.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8c049",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c53029",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=val_generator.classes\n",
    "steps=val_generator.samples // val_generator.batch_size + 1\n",
    "y_pred_prob=model.predict(val_generator, steps=steps, verbose=0)\n",
    "y_pred=(y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "report=classification_report(y_true, y_pred, target_names=[\"closed\", \"open\"])\n",
    "print(report)\n",
    "with open(\"../../results/reports/classification_report_final.txt\", \"w\") as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a0032",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d838c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matirx=confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matirx, annot=True, fmt=\"d\", cmap=\"Reds\",\n",
    "            xticklabels=[\"closed\", \"open\"], yticklabels=[\"closed\", \"open\"])\n",
    "plt.xlabel(\"Pred\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../results/images/confusion_matrix_final.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35c1fd",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ef64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../src/models/Model_final\", exist_ok=True)\n",
    "model.save(\"../../src/models/Model_final/model_final.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c87871",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../webcam_app/model\", exist_ok=True)\n",
    "model.save(\"../../webcam_app/model/model_final.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf210_310)",
   "language": "python",
   "name": "tf210_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
